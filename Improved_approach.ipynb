{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Improved_approach.ipynb","version":"0.3.2","provenance":[{"file_id":"1AfkcORSIShJ1aO3iv6uEpMK9uKGa3vvO","timestamp":1548011930135}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"ko6l3pYqkikO"},"cell_type":"markdown","source":["# Initialization\n"]},{"metadata":{"colab_type":"text","id":"oz-BuPUtilGZ"},"cell_type":"markdown","source":["## Loading of modules & GPU Check\n","\n","This is taken from the baseline code, few other imports e.g.: livelossplot is added to enable live observation of the train/validation loss. Numpy had to be updated to work correctly with pickle. "]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":23248,"status":"ok","timestamp":1549193465199,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"0Vc5yXJRidoN","outputId":"07fb53c1-a6d1-45c9-e720-5e4d66d7a2fd","colab":{"base_uri":"https://localhost:8080/","height":768}},"cell_type":"code","source":["# Taken from\n","# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","!pip install livelossplot\n","!pip3 install --upgrade numpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.0.2)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n","Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.16.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.0.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n","Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n","Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot) (1.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (40.7.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.2)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n","Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.5.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n","Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"1_WWaiuOos7Z","colab":{}},"cell_type":"code","source":["import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","  process = psutil.Process(os.getpid())\n","  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":652,"status":"ok","timestamp":1549189950572,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"1sEu6JLri5SG","outputId":"12211073-27df-4200-8967-b7fe5efeb22f","colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["printm()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Gen RAM Free: 12.9 GB  | Proc size: 142.3 MB\n","GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"gzZdBxMwjKWn"},"cell_type":"markdown","source":["## Download & Unpack the data (Run only if not done already)\n","This block simply downloads the data and unzips it for training/testing. "]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":230177,"status":"ok","timestamp":1549190181389,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"OuY76IEvjSr8","outputId":"c80cd66a-23ed-4431-8062-fdc86f912b3d","colab":{"base_uri":"https://localhost:8080/","height":513}},"cell_type":"code","source":["# Clone repo\n","!git clone https://github.com/alopezgit/keras_triplet_descriptor\n","# Change directory\n","%cd /content/keras_triplet_descriptor\n","!git checkout 719576a29567a9a2b86658496eea7f196bc314f6\n","# Download data\n","!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n","# Extract data\n","!unzip -q ./hpatches_data.zip\n","!rm ./hpatches_data.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'keras_triplet_descriptor'...\n","remote: Enumerating objects: 65, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 65 (delta 26), reused 31 (delta 9), pack-reused 0\u001b[K\n","Unpacking objects: 100% (65/65), done.\n","/content/keras_triplet_descriptor\n","--2019-02-03 10:32:35--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n","Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 185.235.236.197\n","Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|185.235.236.197|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://imperialcollegelondon.app.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n","--2019-02-03 10:32:35--  https://imperialcollegelondon.app.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n","Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 185.235.236.199\n","Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|185.235.236.199|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://public.boxcloud.com/d/1/b1!LVEG5EB8udk_Dwljj3b86KRUFfpK9mzdrf1bBRTFoz0UdpRifPp1CIMWI8H_lrXhv_aCQHlPO8Zskbby18fHFeMDTtgCKqYeD0eWOpjkhrxSJT0jybzBIuAt7TzuXTZb5BoYFVydhOH5BO9G7EraTpl8T_N6kPyGFhpAGqyXBiIkpozGk95XlmjdLAJRtmQPep0upfHbnPSlPr2rZDP4sGx32EQTP7OqdpQnM8mMMuRBL4WlOkJc_GIqe-pBPQ643RQeYOqSKJA1pfXoJEQgpUzpq0XzRoyXe9nFBn-P55xVYY2IkwWtR-HIc0IvT_PvpqrW6r41oENOOnUWil6uXXfQcC_cljsk3spOLERVAHxb1IuNlUYOip3KgkN7lp9pQx6-xYgwHHssNDDidfHYFxavxKmxV-YrtZgcJ5fX5G5zi9camukxXYXRW_eJiqJ6u9VdeMm4coxSHSDaAHRTX1269wzqrjBhVgs0fj2RvFIfttGQPHkF8nB1NS6jQUxHnHcLQlN4pcw4FgVa-3S-gk6Sz1aHbTUMXujh2wv25ZOD5ZN54ynFX466wQadcxiwKFx0_mKlRbkpZ2V8rKDuAsBft0wAD2GQKdtcdTvsj5U-9i1a6cMfQcSyuCxLFXKiLrKQNt9abvlVYd7N_Ao2Kx4RhQvjEPTGHxEL-WrtEkk35fyqD9Nt1MioLVhdB7R0cGqo6vdbP5SYVBgv3bWPliOrFqRJSF44W7Nt4XxFWrkdaPnG9Hzotdqw8uPEAg0u9GXoLa7X4lSRfzHEDXDeqM77fi3SNe4gBSz1QQkKnUv88bYf7b-54xtIBJCB8KfVmM2XiHOjUxxJjNHpoCDbgTQckxUgQvfN9nsFqbu4I-k0sRlnUIzVVRAvvXxMfSEeJEU9GqkwWAZQP-5Ioxshq8EL3eqb560jfHtFdGTm43oF8XgIRUGvGedRlJ7otF-OnarqQfGrPGbGzV-fIo-ipfchbU-Wv_SmPHvSrszmdtbTvDTjNOizwexh9jfVxCRtUpRx5Ds8MyD3XFB7Egy4hEMNNKk9vekZa6bCC7e_kVnt1vhdZkFjJlAk_q9rP7jK1e1AgrB4m_9nM_6ij5N1d0BtApoMcQZiz6316OtF7cyZvguM_DcFTg7BtwrjZue-zwV2cq8iOe-YV8bbz2Dq_Yse9BZDZLdZW0JAc-_F0Z5iVlWUhLZLigm9fFQDJxQzWn0JgEbHEcXR_yntki6OuFtW6VDhfduo5v_pio9oCi9t-9gK6pk-CLqhn0jWQ-DML0M3AwQKySOnqhOOT0TTD8-fzpyOjTLg60S5FDXe6VjH72K9uCv6GOT3T0Ls792v_Uo8oSebBFEtDzFIp4YbqX7XzDqm3jbum2kgsZlKLiM03rN-Eu7c8YIrYvOz-0KXAnLMS6AZVVCadP7UyPhuABqU5s2qkPiiFLAr16Tkx3jVUfvV/download [following]\n","--2019-02-03 10:32:36--  https://public.boxcloud.com/d/1/b1!LVEG5EB8udk_Dwljj3b86KRUFfpK9mzdrf1bBRTFoz0UdpRifPp1CIMWI8H_lrXhv_aCQHlPO8Zskbby18fHFeMDTtgCKqYeD0eWOpjkhrxSJT0jybzBIuAt7TzuXTZb5BoYFVydhOH5BO9G7EraTpl8T_N6kPyGFhpAGqyXBiIkpozGk95XlmjdLAJRtmQPep0upfHbnPSlPr2rZDP4sGx32EQTP7OqdpQnM8mMMuRBL4WlOkJc_GIqe-pBPQ643RQeYOqSKJA1pfXoJEQgpUzpq0XzRoyXe9nFBn-P55xVYY2IkwWtR-HIc0IvT_PvpqrW6r41oENOOnUWil6uXXfQcC_cljsk3spOLERVAHxb1IuNlUYOip3KgkN7lp9pQx6-xYgwHHssNDDidfHYFxavxKmxV-YrtZgcJ5fX5G5zi9camukxXYXRW_eJiqJ6u9VdeMm4coxSHSDaAHRTX1269wzqrjBhVgs0fj2RvFIfttGQPHkF8nB1NS6jQUxHnHcLQlN4pcw4FgVa-3S-gk6Sz1aHbTUMXujh2wv25ZOD5ZN54ynFX466wQadcxiwKFx0_mKlRbkpZ2V8rKDuAsBft0wAD2GQKdtcdTvsj5U-9i1a6cMfQcSyuCxLFXKiLrKQNt9abvlVYd7N_Ao2Kx4RhQvjEPTGHxEL-WrtEkk35fyqD9Nt1MioLVhdB7R0cGqo6vdbP5SYVBgv3bWPliOrFqRJSF44W7Nt4XxFWrkdaPnG9Hzotdqw8uPEAg0u9GXoLa7X4lSRfzHEDXDeqM77fi3SNe4gBSz1QQkKnUv88bYf7b-54xtIBJCB8KfVmM2XiHOjUxxJjNHpoCDbgTQckxUgQvfN9nsFqbu4I-k0sRlnUIzVVRAvvXxMfSEeJEU9GqkwWAZQP-5Ioxshq8EL3eqb560jfHtFdGTm43oF8XgIRUGvGedRlJ7otF-OnarqQfGrPGbGzV-fIo-ipfchbU-Wv_SmPHvSrszmdtbTvDTjNOizwexh9jfVxCRtUpRx5Ds8MyD3XFB7Egy4hEMNNKk9vekZa6bCC7e_kVnt1vhdZkFjJlAk_q9rP7jK1e1AgrB4m_9nM_6ij5N1d0BtApoMcQZiz6316OtF7cyZvguM_DcFTg7BtwrjZue-zwV2cq8iOe-YV8bbz2Dq_Yse9BZDZLdZW0JAc-_F0Z5iVlWUhLZLigm9fFQDJxQzWn0JgEbHEcXR_yntki6OuFtW6VDhfduo5v_pio9oCi9t-9gK6pk-CLqhn0jWQ-DML0M3AwQKySOnqhOOT0TTD8-fzpyOjTLg60S5FDXe6VjH72K9uCv6GOT3T0Ls792v_Uo8oSebBFEtDzFIp4YbqX7XzDqm3jbum2kgsZlKLiM03rN-Eu7c8YIrYvOz-0KXAnLMS6AZVVCadP7UyPhuABqU5s2qkPiiFLAr16Tkx3jVUfvV/download\n","Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n","Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4088106554 (3.8G) [application/zip]\n","Saving to: â€˜hpatches_data.zipâ€™\n","\n","hpatches_data.zip   100%[===================>]   3.81G  21.2MB/s    in 3m 6s   \n","\n","2019-02-03 10:35:42 (21.0 MB/s) - â€˜hpatches_data.zipâ€™ saved [4088106554/4088106554]\n","\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"goZc5cZ4j8lu"},"cell_type":"markdown","source":["## Imports of modules"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":208331,"status":"ok","timestamp":1549190183851,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"J-v-E5oJkAG2","outputId":"41ee67e2-99f1-4b7d-cb28-1a23d01970e3","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import sys, json, os, glob, time, cv2, random\n","import keras\n","from keras import backend as K\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Dense, Activation, Flatten, Input, Lambda, Reshape, Subtract, AveragePooling2D, Add\n","from keras.layers import Conv2D, BatchNormalization \n","from keras.layers import Input\n","from keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from keras.regularizers import l2\n","from keras.optimizers import Adam\n","from keras.utils import plot_model, np_utils\n","\n","\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","\n","\n","from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n","from utils import generate_desc_csv, plot_denoise, plot_triplet\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"colab_type":"text","id":"cTNW3xJ9k06U"},"cell_type":"markdown","source":["## Fixation of seeds \n","\n","We keep the seeds for random number generators fixed so that the results are reproducible. "]},{"metadata":{"colab_type":"code","id":"65gGLRgxkxRs","colab":{}},"cell_type":"code","source":["random.seed(1234)\n","np.random.seed(1234)\n","tf.set_random_seed(1234)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"v9gGGQEwlAmG"},"cell_type":"markdown","source":["## Loading of splits\n","\n","Here we load the train and test data both locations for the descriptor network and also for the denoising network. \n","\n","The winning model contained 2 networks.\n","\n","The denoising network contained 3 7x7 Convolution, 5 5x5 Convolutions and 9 3x3 Convolutions, while the depth of the model was 128 filters. \n","\n","The descriptor network used ResNet v2 with the depth of 20. \n","\n","The models are visualised while being loaded in their respective blocks. You can find the visualisations in the `keras_triplet_descriptor` folder as `.png` images.  \n","\n","Note, that the visualisation of the loss function is not working beacuse there are some internal compatibility issues between numpy and pickle. The plots were orginally generated on an external server outisde the Colab environment. "]},{"metadata":{"colab_type":"code","id":"k4vpUTBPlDV_","colab":{}},"cell_type":"code","source":["# If you wish to train from scratch, set training to True\n","denoise_train = False\n","descriptor_train = False\n","plot = True\n","\n","# Define the parameters for the winning models\n","denoise_layer_n = [3,5,9]\n","denoise_filters = 128\n","descriptor_depth = 20\n","\n","hpatches_dir = './hpatches'\n","splits_path = './splits.json'\n","\n","splits_json = json.load(open(splits_path, 'rb'))\n","\n","split = splits_json['a']\n","\n","train_fnames = split['train']\n","test_fnames = split['test']\n","\n","seqs = glob.glob(hpatches_dir+'/*')\n","seqs = [os.path.abspath(p) for p in seqs]   \n","seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n","seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"v31Msj2pmCer"},"cell_type":"markdown","source":["# Model definitions\n","\n"]},{"metadata":{"colab_type":"text","id":"eBzsYIUjqmkf"},"cell_type":"markdown","source":["## Denoise Model\n","\n","The denoise model is closely following DNCNN [Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising](https://arxiv.org/abs/1608.03981)\n","\n","The original code can be found here: https://github.com/cszn/DnCNN/tree/master/TrainingCodes/dncnn_keras.\n","\n","The difference between the original network and this implementation is in in inclusion of 2 more subtraction blocks with varying number of kernel sizes, while the number of filters stays constant. "]},{"metadata":{"colab_type":"code","id":"MAiVSsK5mSzU","colab":{}},"cell_type":"code","source":["SHAPE = (32, 32, 1)\n","\n","def denoise_residual_block(inpt, depth = 2, filters = 32,\n","                           kernel_size = 3, strides = 1):\n","\n","  n = inpt\n","  for i in range(depth):\n","    n = Conv2D(filters=filters, kernel_size=(kernel_size,kernel_size), strides=(strides,strides),\n","             kernel_initializer='he_normal', padding='same',kernel_regularizer = l2(1e-4))(n)\n","    n = BatchNormalization()(n)\n","    n = Activation(\"relu\")(n)\n","  return n\n","\n","    \n","  \n","def get_denoise_model(shape,filters, n_nodes):\n","  inpt = Input(shape=shape)\n","  \n","  x = Conv2D(filters=filters, kernel_size=(9,9), strides=(1,1),\n","             kernel_initializer='orthogonal', padding='same', kernel_regularizer = l2(1e-4))(inpt)\n","  \n","  n1 = denoise_residual_block(x, n_nodes[0], filters, 7, 1)\n","  y = Subtract()([x, n1])   # input - noise\n","  n2 = denoise_residual_block(y, n_nodes[1], filters, 5, 1)\n","  y = Subtract()([y, n2])   # input - noise\n","  n3 = denoise_residual_block(y, n_nodes[2], filters, 3, 1)\n","  y = Subtract()([y, n3])   # input - noise\n","  \n","  out = Conv2D(filters=1, kernel_size=(1,1), strides=(1,1),\n","             kernel_initializer='orthogonal', padding='same', kernel_regularizer = l2(1e-4))(y)\n","\n","  model = Model(inputs=inpt, outputs=out)\n","    \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"qELeYePpqodm"},"cell_type":"markdown","source":["## Descriptor model\n","\n","Descriptor model copies the original ResNet v2 from [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027).\n","\n","The original code can be found here: https://github.com/broadinstitute/keras-resnet.\n","\n","The main difference is that the last layer was adapted to produce a 128-dimensional output to match the specification and the input dimensions into the HPatches framework. The original combination of the descriptor networks to match the triplet loss was not changed from the baseline."]},{"metadata":{"colab_type":"code","id":"rtdONMtyr5Gm","colab":{}},"cell_type":"code","source":["def residual_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","\n","def get_descriptor_model(input_shape, depth=20):\n","    if (depth - 2) % 9 != 0:\n","        raise ValueError('Depth should be 9n+2 (eg 56 or 110)')\n","    \n","    # Start model definition.\n","    num_filters_in = 8\n","    num_res_blocks = int((depth - 2) / 9)\n","\n","    inputs = Input(shape=input_shape)\n","    x = residual_layer(inputs=inputs,\n","                     num_filters=num_filters_in,\n","                     conv_first=True)\n","\n","    # Instantiate the stack of residual units\n","    for stage in range(3):\n","        for res_block in range(num_res_blocks):\n","            activation = 'relu'\n","            batch_normalization = True\n","            strides = 1\n","            if stage == 0:\n","                num_filters_out = num_filters_in * 4\n","                if res_block == 0:\n","                    activation = None\n","                    batch_normalization = False\n","            else:\n","                num_filters_out = num_filters_in * 2\n","                if res_block == 0:\n","                    strides = 2\n","\n","            # Bottleneck residual unit\n","            y = residual_layer(inputs=x,\n","                             num_filters=num_filters_in,\n","                             kernel_size=1,\n","                             strides=strides,\n","                             activation=activation,\n","                             batch_normalization=batch_normalization,\n","                             conv_first=False)\n","            y = residual_layer(inputs=y,\n","                             num_filters=num_filters_in,\n","                             conv_first=False)\n","            y = residual_layer(inputs=y,\n","                             num_filters=num_filters_out,\n","                             kernel_size=1,\n","                             conv_first=False)\n","            if res_block == 0:\n","                x = residual_layer(inputs=x,\n","                                 num_filters=num_filters_out,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","                \n","            x = Add()([x, y]) \n","\n","        num_filters_in = num_filters_out\n","\n","    # Cater for the input dimensions of HPatches\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=\"he_normal\")(x)\n","    x = Reshape((128,))(x)\n","\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","def get_descriptor_model_connected(shape, depth):\n","  xa = Input(shape=shape, name='a')\n","  xp = Input(shape=shape, name='p')\n","  xn = Input(shape=shape, name='n')\n","  descriptor_model = get_descriptor_model(shape, depth)\n","  ea = descriptor_model(xa)\n","  ep = descriptor_model(xp)\n","  en = descriptor_model(xn)\n","\n","  loss = Lambda(triplet_loss)([ea, ep, en])\n","  model = Model(inputs = [xa, xp, xn], outputs = loss)\n","  return model, descriptor_model"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"uq5Dy9cHnX45"},"cell_type":"markdown","source":["## Loss definition\n","\n","Define the same loss as used in the baseline method for the descriptor network. The denoising architecture uses mean-squared error and does not need a separate function for the loss. "]},{"metadata":{"colab_type":"code","id":"DFa-BIg8naT7","colab":{}},"cell_type":"code","source":["# Descriptor loss\n","def triplet_loss(x):\n","  output_dim = 128\n","  a, p, n = x\n","  _alpha = 1.0\n","  positive_distance = K.mean(K.square(a - p), axis=-1)\n","  negative_distance = K.mean(K.square(a - n), axis=-1)\n","  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"2fz78fWonnWw"},"cell_type":"markdown","source":["# Training: Denoise model\n","\n","For the collection of the results that gave the starting insight the parameters are summarized in the comments below. We define a set of callbacks to limit the training such that the model avoids overfitting/underfitting.\n","\n","## Loading of the data"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":102908,"status":"ok","timestamp":1549191152622,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"xxBhuypUnq3h","outputId":"7f6002bb-e0b4-453e-9d21-a91772c639dd","colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["# Denoising data\n","denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n","denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:01<00:00,  1.08it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:38<00:00,  1.02it/s]\n"],"name":"stderr"}]},{"metadata":{"colab_type":"code","id":"Ah49YkCdoOPG","colab":{}},"cell_type":"code","source":["#Training: steps_per_epoch = 31179, validation_steps = 19050, epochs = 20\n","#Collection of results as plotted in figures: steps_per_epoch = 2000, validation_steps = 200, epochs = 2\n","denoise_model = get_denoise_model(SHAPE, denoise_filters, denoise_layer_n)\n","denoise_history = None\n","\n","def lr_schedule_denoise(epoch):\n","    initial_lr = 0.001\n","    if epoch<=5:\n","        lr = initial_lr\n","    elif epoch<=10:\n","        lr = initial_lr/10\n","    elif epoch<=15:\n","        lr = initial_lr/20 \n","    else:\n","        lr = initial_lr/20 \n","    return lr\n","\n","# Define the callbacks\n","early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1, mode= 'auto')\n","lr_scheduler = LearningRateScheduler(lr_schedule_denoise)\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)  \n","\n","callbacks_list = [early_stopping, lr_scheduler, lr_reducer]\n","denoise_model = get_denoise_model(SHAPE, denoise_filters, denoise_layer_n)\n","denoise_model.compile(optimizer=Adam(0.001), loss='mean_squared_error')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":4434,"status":"ok","timestamp":1549193659316,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"fHjy1dlnaNCs","outputId":"cabe77b6-2abb-4842-ec28-56aeea7a6c8d","colab":{"base_uri":"https://localhost:8080/","height":2142}},"cell_type":"code","source":["# Plot the architecture of the model together with its summary and number of trainable parameters\n","if plot == True:\n","  plot_model(denoise_model, to_file='improved_denoise_arch.png')\n","  print(denoise_model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            (None, 32, 32, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 32, 32, 128)  10496       input_7[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 32, 32, 128)  802944      conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 32, 32, 128)  512         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 32, 32, 128)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 32, 32, 128)  802944      activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 32, 32, 128)  512         conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 32, 32, 128)  0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 32, 32, 128)  802944      activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 32, 32, 128)  512         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 32, 32, 128)  0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","subtract_16 (Subtract)          (None, 32, 32, 128)  0           conv2d_103[0][0]                 \n","                                                                 activation_91[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 32, 32, 128)  409728      subtract_16[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 32, 32, 128)  512         conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 32, 32, 128)  0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 32, 32, 128)  409728      activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 32, 32, 128)  512         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 32, 32, 128)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 32, 32, 128)  409728      activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 32, 32, 128)  512         conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 32, 32, 128)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 32, 32, 128)  409728      activation_94[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 32, 32, 128)  512         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 32, 32, 128)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 32, 32, 128)  409728      activation_95[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 32, 32, 128)  512         conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 32, 32, 128)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","subtract_17 (Subtract)          (None, 32, 32, 128)  0           subtract_16[0][0]                \n","                                                                 activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 32, 32, 128)  147584      subtract_17[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 32, 32, 128)  512         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 32, 32, 128)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 32, 32, 128)  147584      activation_97[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 32, 32, 128)  512         conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 32, 32, 128)  0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 32, 32, 128)  147584      activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 32, 32, 128)  512         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 32, 32, 128)  0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 32, 32, 128)  147584      activation_99[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 32, 32, 128)  512         conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 32, 32, 128)  0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 32, 32, 128)  147584      activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 32, 32, 128)  512         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 32, 32, 128)  0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 32, 32, 128)  147584      activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 32, 32, 128)  512         conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 32, 32, 128)  0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 32, 32, 128)  147584      activation_102[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 32, 32, 128)  512         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 32, 32, 128)  0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 32, 32, 128)  147584      activation_103[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 32, 32, 128)  512         conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 32, 32, 128)  0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_120 (Conv2D)             (None, 32, 32, 128)  147584      activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 32, 32, 128)  512         conv2d_120[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 32, 32, 128)  0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","subtract_18 (Subtract)          (None, 32, 32, 128)  0           subtract_17[0][0]                \n","                                                                 activation_105[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_121 (Conv2D)             (None, 32, 32, 1)    129         subtract_18[0][0]                \n","==================================================================================================\n","Total params: 5,805,057\n","Trainable params: 5,800,705\n","Non-trainable params: 4,352\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"dVc0sGZs4w4i","colab":{}},"cell_type":"code","source":["# If previously defined that we are training, train it from scratch\n","# If not simply load the history from a file\n","if denoise_train == True:\n","  denoise_history = denoise_model.fit_generator(generator=denoise_generator,\n","                                                epochs=20,\n","                                                verbose=1,\n","                                                callbacks=callbacks_list,\n","                                                validation_data=denoise_generator_val,\n","                                                workers=1,\n","                                                steps_per_epoch = 31179,\n","                                                validation_steps = 19050,\n","                                                use_multiprocessing=False\n","                                               )\n","  denoise_history = denoise_history.history\n","else:\n","  with open('improved_denoise_history.pck', 'rb') as file_pi:\n","    denoise_history = pickle.load(file_pi, encoding='latin-1')\n","  denoise_model.load_weights('improved_denoise.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":8956,"status":"ok","timestamp":1549193731314,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"QnA-klAg_BCB","outputId":"3b830685-4dd4-4488-9760-5703b3ec09d2","colab":{"base_uri":"https://localhost:8080/","height":113}},"cell_type":"code","source":["# Plot the intermediate results wheile filtering an image from noise on a random image.\n","# Plot what has each noise-loop learned and how it approaximately removes the noise from the distorted image\n","# The activations have to be manually specified because their name changes every time :( \n","\n","if plot == True:\n","  img = denoise_generator_val[np.random.randint(0, len(denoise_generator_val))][0][0]\n","  _img = np.expand_dims(img, 0) \n","  model_layers = [ layer.name for layer in denoise_model.layers]\n","  subtract_layers = [i for i in model_layers if \"subtract\" in i]\n","  subtract_layers = [\"activation_91\", \"activation_96\", \"activation_105\"]\n","  subtract_extractors = [Model(inputs=denoise_model.input, outputs=denoise_model.get_layer(i).output) \n","                         for i in subtract_layers]\n","  \n","  output = denoise_model.predict(_img)\n","  \n","  fig, axs = plt.subplots(1,len(subtract_layers) + 2)\n","  plt.axis(\"off\")\n","\n","  fig.tight_layout()\n","  axs[0].set_title(\"Original Image\")\n","  axs[0].imshow(img.astype(np.uint8).reshape((32,32)), cmap='gray')\n","  axs[0].grid(False)\n","\n","  \n","  for i,extractor in enumerate(subtract_extractors):\n","    features = extractor.predict(_img)\n","    axs[i+1].imshow(features[0, :, :, np.random.randint(0, 128)], cmap='gray')\n","    axs[i+1].set_title(\"{}. Noise\".format(i+1))\n","    axs[i+1].grid(False)\n","\n","    \n","  axs[len(subtract_layers)+1].imshow(output.astype(np.uint8).reshape((32,32)), cmap='gray')\n","  axs[len(subtract_layers)+1].set_title(\"Output\".format(i+1))\n","  axs[len(subtract_layers)+1].grid(False)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaMAAABgCAYAAACwnh1aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXl4ldXV6H9kJgQCMoQwS4wbmUTQ\nAkIUBRRnsBWKRe2teutU236f1fba79O29nqtrUPbex1qrbafFfyqqIgihCIqg1BEQYatgEGBAAlj\nEkggw/1jn73yJmQ4J5zkBFi/5+Hh5D3vfod19vuuvdZea+02VVVVKIqiKEosiYv1BSiKoiiKKiNF\nURQl5qgyUhRFUWKOKiNFURQl5qgyUhRFUWKOKiNFURQl5iRE2sAY0wa4G7gFSMQptEXAz621BfW0\nWQj8xFr7cQPHfRjYaq19OtJrCrV/EOhlrb2l1vZ+wCZrbcT3eqJgjEkE/g/wb0Bva+22MNo8CPwM\nGGit3RzY/h7woLX2vQbaTgGustZ+7/iuvPVijLka+CWQDOwBbrPWftZImwdRmdaJMeabwH8AKUAh\nKs+o05R3c6DtrdbaPx3HuQ2QYa19v6nHaIpl9GvgO8Bl1toBwEBgP/CeMaZtXQ2steMbUkShfX7W\nVEWk8AZQ3IR2O4DfRtrIWjv7ZH7IjTE9gReB6621ZwF/B54Js7nKtBbGmD7A08A1oXfGfwPPh9lc\n5Rk+Eb+bAYwx3YF7j/PcU4ALjucAEVkLxpjTgB8Bw/zo21pbDtxnjBkP3AA8a4zJw3W27wATgfeB\nGdbaD40x/yt0jK3AX4B7rbX9jDEv4CyYh0LtHwZuBnoDf7fW/nvoGm4B/j107fnADdbarRHcQxXw\nP3EjiI7ATcCtwPnAetxoqjw0Mv41kIR70d9srf3EGBMHPAlcB2wC5uB+/HHGmI7AH4CRoev7lbX2\nL+Fe23HwK2vtMmPMf0bY7r+Aq40xF1lrF9X+0hgzFHgK6AyUAvdZa981xnwX93tOMMZcCDyOG/G2\nAf7TWvvfMZRFNDgKTLfWrg/9/SHwv8NsqzI9lqM4xe6f04U4qzMcVJ5hEM672RjzDAHPSehd2Bv3\nfu5ljNkIDAXKgB8C3wN64OT1dFCmofbfBWbg3oc/A44YYzr5d3WkRGoZjQK+stZ+Xsd3c4ALA3/3\nstYaa+1XfoMxZhBOA58N5ABTGzjXBcBoYATwA2NML2NMN+CPwERrbTZOGfxHhPcA0MVaOwSYBbwK\nPACcCQwBLjTGJOBGxrdaaw3O8vCjs8uBy4AzgKuB7waO+zugEhiA6+C/MMYMbsL1RYS1dlkTm1bg\nXHtPGGPig1+ElO5M4I+hUdYtwMvGmPa1jvFb4MfW2oE4eUwJbY+JLKKBtXa3tXZeYNNlwEdhNleZ\n1sJam2+tXQAQera+i3umwkHlGR6RvJtr871Q2wHW2iOhbdnW2mG49/QTxpjO9TW21s4BZgNPNlUR\nQeTK6DSgPt/jrtD3nrfq2OcC4L1Q5yylYVP979baCmvtjtCxe1trdwMdAnMiHwD9I7oDx+uh/9cC\nm621n1try4AvgB6hEUU3a+3yOs6TA7xlrS221u4FXg4c9yrcD1IZ8tG+BlzbhOtrMay1C4E83IMc\n5HSgO+5hx1r7L5w1e16t/XYDNxpjBlhrv7DWXh/afsLJoi5Co8ofh/6Fhcq0bowxP8Q9yznAfeG2\nU3mGRSTv5nB4HsBaawELfKPplxYekU7qF+LMtrrIwP3onr117NOp1vbtDZzrQOBzBRAfGhn9MuRC\niwfaA3WNBBqjKHDc4FxLRei4AHcbY27CTWCnAL6IXycgGCAQvIeOwCvGmPLQ321x/vHWzj3AImPM\nzMC2rsB+a22weOE+oFuttt8Dfg7kGmMOAz+z1v6DE1cWgjFmMs6Nc2XAZRcuKtNaWGufNMb8Hvg2\nsNQYM9BaezjM5irPhonk3RwOwff0Ptx7r1mJVBktA04zxpxtrf201ndX4h7chjgIpAX+zozw/NNw\nZvYF1tpCY8ytuHmpqGKMOR83cvuGtTbPGDMR8JEmDd3DDmCybSRKqLVhrf3CGDOLmi7PXbjfuk3g\nYe8c2t430HYX8AOcK/US4DVjzDxOUFl4jDETcL7wS6y1GyJtrzKtxhhzFtDTWpsbuu+XjTF/BAzw\nSTjHUHk2Sjjv5hmEBtvGmMaUSxeclQnOqtqLU/5BV2lUFVREbjpr7QHcpP7fjDGng/MBh8Ky4wmZ\nyw2wArjIGNPFGJOMCx6IhG5AXkgRdcbNOaU10qYpdMONJL4yxqTirrNdKHRyBXClMaZtaAI0OO/1\nBnAbiFweN8YMb4braw5+CUyn+iHOw1mA00AUdHfc/RPalmiMec8Y4xXyKtxkdSUnsCxCv/lfgGub\noogCqEwdXYG/GmN6ABhjxuBCj7dEeByVZz2E+W7Ox83Xg7MWK0OfjwJpofk8z/TQMc4CsnFzpvlu\nk0kJPSPfCux/FGdpNpmIQ7uttb8FngXmhKIv1uM054TA5Fd9bVfgAgNWA//ETaxFsobFy0BnY8ym\n0OefA72NMb+L9D4awY+aNgPzgSdwbsN/4Cbq/oXzo74KvEL1PfwHkG6MscA6XCdYE+Vrq4ExJsMY\nszH0W4AL49xojOkZ+hfWqC/UmR8C+oX+rsK5U+4yxmwAfg9cZ60tCbQ5CjwHLDTGrAcWAz+w1h4i\nBrKIItfgXqAvedmG/mWoTCPHutyTX+PcZBuB/wd821p7UOUZPcJ4N98PPGWM+QQowXl5wN3zXmCn\ncWH4ALtD+70P3G2t3YfLWfoINzXyDjWDUOYAtxlj/tHU62/T0usZBU1qY8wVwEPW2nNa9CKOk1r3\ncCfux57SSDNFUZRWjwmFfNswkuejSYtWJTDGdAU2hkzhr3AurqaGJccEY8ww4HVjzDm4QIhrgXdj\ne1WKoignNi1amy4UPnk/Luntc5wJ+WBLXsPxYq39BOdqXAVswEXT/TGmF6UoinKC02Q3nTHmcVyi\nVRXwQ2vtymhe2KmGyjP6qEyji8pTaU6aZBkZV14j21o7Gley5/dRvapTDJVn9FGZRheVp9LcNNVN\nN55QFYNQ6GsnY0yHqF3VqYfKM/qoTKOLylNpVpoawNAdN2fiKQhtO1jXzp07d64CGDlyJIcOHQIg\nLy+Pc845Rz4XF7tCCB06dODgwZqHiYuL44ILXEHYzz77TPY97bTTyMx06QOlpaUAXHXVVWzb5oJA\nVq9eTY8eLik5IyODLVtcWkNRUZEcu2PHjtL+6NGjcj29e/cG4K677uLLL78E4Oabb24TnngiJiJ5\nArRp06ZlwyCbiaqqqlYh02jKs2/fvtJ/iouLueSSSwB4910X51JSUsIdd9wBwN69e3n+eVcV68or\nr2Tfvn0AdOrUic8/d8VFvvrKlXf0/RcgNTWVSy+9FIDXXnuN22+/HYCnnnrqpJNnLGnG/hkRCQkJ\nVaH/KS8vD24HqLENoKKi4phjxMe7fNWUlBS6du0KQFZWFgMHDgTgrLPOApC+C1BQUMCuXbsAOHDg\ngLxny8rKjjlnQkKCXE/nzp05/fTTATjvvPPk2LhCtXUSrQCGVvGDnUSoPKOPyjS6qDyVqNJUy2gH\nblTk6YHLzq2TM888E4D8/HzatWsHQJs2bSgsLJR9kpKSAEhLSxPLpnt3d4rS0lL+/Oc/A3D22Wdj\njAFqjgb8SGDt2rWMHj0agO3bt/P1118Dzrr65BNXeWTEiBFs3rxZjg3OQkpLc8UccnJyxHp67rnn\nuOiii8KTStOJSJ5KWMRMplu3bmXr1upVTXwf8/01Pz+fNWtcbuXQoUNlJFpUVESHDs7zNWbMGM47\nz9X79Bb7zJkz+ewzlx8aFxfHpEmTAFi6dCl9+vhcxWZD+2groLY1Uvtvj7eCPEFLKWjBJCQkkJyc\nDDiLqfb+5eXllJS4HOKSkpIafbm29VVeXi7HLS0tlXa7d+8mIyMDcN6s+miqMpoP/AJ4JpQztMNa\nW1Tfzvv37wecy6JzZ1eJvKioSJTO4MGD2blzJ+DcFt6E9K65+fPn07NnT8DdsFcklZWVong6dXJl\nkkpLS1m0aJF8v3GjK0yQnZ0tD2yPHj3Iy8sDnBkKsG/fPjlGQkKCuOb69OlTwz3STEQkTyUsYirT\nLl26ADBp0iT27NkDVPe1Xr16yfeJiYn4iNb8/HxxzcXFxTFo0CAAcTWnp6eL4srMzOTee916aI88\n8giXXXZZc9+S9tGThPj4eFEaqampMgj3SikxMVEUTVABlZaW1qv8wCkwf1xwrjxw73//DDSkjJrk\nprPWLgVWGWOW4qJq7mzKcRSHyjP6qEyji8pTaW6aXIHBWvvTcPf1JmNWVhabNm0CYPTo0eI227lz\np2jUvLw8GQkuX+6WE0pLSxPLKScnRwIYBgwYwL/+9S8A+vXrB8AVV1zBW2+9Jef1Wn/NmjVilX39\n9df07etqLXrLqWvXrmIZbd26lTPOOANwFtWBA8HVLJqHSOSphEesZJqens6ECRMAuPzyy8WS/8c/\nXNmuzZs3i6s5aLHPnj1bLJ/09HTcUjKwYMECABYtWkR2djbgnpMjR1wpyNzcXOn/zYn20ROXoNsu\nISFBXHIpKSliEfkplJSUlBruOG/h+P/98Wq7An1bf47g9+G8Q1ukHJBXAnl5eTIPlJqaKjd3+PBh\n1q93y8WMHDlS3Hf+wYyLixPl8cUXX4jwtm3bJsrGR+DNmzdP2q1fv56srCzAzSUFhdO2rVsS3gu9\nbdu24ucfMmSIKKbt27fXGZmiKFDtHt63b5/0y969e8t86Jo1a6TftW/vFiDds2cPu3e75WXmzp0r\n80AVFRWMGjUKcArLu4p9xGdmZiZDhw4FwFrLddddB8C4ceNqRIgqSl0E54m80khLS6uhhODY+aa6\nXHO15508/hlITk6W41VUVMh7tiFatByQoiiKotRFi1hG3p3Qtm1bUlNTAece89ZOfHy8TNYWFxeT\nk5MDwMqVrtrIzp07xQLq3r27TIKlpqYyZMgQwFlX4CZ7vUsvJSVFXB3Dhg2Tdlu3bpV2/rjeNQhu\n5Nq/v1tlfNOmTRJQoSi18XlBUD1CLC4ulj5YWVkpo8KxY8cCziXsI+QWL14srmJwUabgcuT88b7z\nHbd+ZFFRkQTsvPXWW/JcZWdny2dFCYegm86/A4Pb6iOYq1Tboqr9vSfo6muIFlFGPjE1Pz+f7dvd\nKt1xcXHi4igsLJSHumPHjpIY60MDMzIyxIU2atQocUls3LiRuDhn3PnoJGMM8+fPB5zf3fvYV6xY\nwZgxYwD3AvF+ev8QV1VVMWzYMADWrVvHvHnzALjpppvEhagoDeH766FDh7j44osBF5b9xBNPHLPv\n+eefDyAh3h7ft7dv3y4K68UXXwRcUqx/fnbs2MHixYsB9yxdffXV0b4d5SSjrnDu5ORk+VzXHFCw\nXe3vvcLx7YOUlpbWeb6GUDedoiiKEnNaxDL6+OOPAeduu/766wFYtmyZjCQvuOACXn75ZQAGDRok\neUnf/OY3Afj888/p1asX4IIhfALVoUOHZKLYByQ8+uijYuFkZGSwcOFCwOUy5efnyzn8+b71Lbdy\nbn5+Pm+++Sbg8kD8KCA3N7fGBJ2iBPEjvqlTp4oFPXDgwGMCa6A6x6JPnz7Sn+Pi4qisrJR9fD7d\nhAkTxFvg+3vfvn2ZNm0a4HKW/MTy6NGj5dyXX355M9ylcqJR1zvLb0tKSqrhkqvLPefff8GouNql\niGoHJZSXl9f43rvmGspNqnF9Ye11nPgHc9q0aRLmevjwYdLT0wH48ssv5SHcuHGjzB/5JMGDBw+K\ngmrfvr3sW1hYKAmDPgopPT1d3Btz584Vv+bgwYPFN79kyRK+/e1vA0gYePv27cV1t2XLFkaOHAm4\nKLyGErWUUxv/wM2fP18iRY8cOSIPoK+oANWu5ClTpoj7eMuWLZKeAIgbrqSkRNzbftD2k5/8RPr7\nrFmzZN/JkydLxJ1yahFUOr7PNTZ4TkhIkOmN5OTkY9xvtdsH3W3+HMEE2PrCtoPHCWdAr246RVEU\nJea0iGXkLZmioiJxSfhoNoAPPvhAqroGo+E2bNgAONeDT0J94IEHJNpu3759TJkyBaiu33X11Vfz\n7LPPAs4t4l0dH330kYxMu3XrxmOPPQZUB1ckJCRI+aGCggKxooYMGSIRTopSH7t27RIr6eKLL5a+\nG3TB+RqN48aNk2fC15+DmnXAJk+eLFaQd8ElJibKCHPYsGGS/P3pp59y4403Ntu9Ka2Tuqyihqgr\nQCHohvMu54qKCsmtDJYOCuYWBSPk/Ls3SGJiohw3Pj5eAxgURVGUE4MWsYx8CPe8efMkZ2f37t10\n69YNcOtoeI1bWVkpn73mfemll2R+adCgQeIfz8rKkgAGv+bLmjVrZMI3WFVh3LhxMu/UvXt3sXa8\n5VRRUSFzQ8OGDWPu3LmAGwF4/76iNITvX48//rj45AcPHizfjx8/HnCVSHxgzQcffCBzowkJCdJf\nx44dy4gRIwB45ZVXANdX161bB7jRqO/zwZwj30Y5+anPGqpve7CSTGJiIuD6nP8crNQdDFrwgQ3B\n7WVlZWLF+3ZHjx6tcaxgzlE4VWxaRBm9//77AAwfPlwemm7dusn2AQMGiAAzMjKkfp13cZSVlclD\nvWrVKlnSITc3lxtuuAFAkmmXL18uD3pmZqa4Qz744APZZ+rUqbL9D3/4A+Ci9HzU3+rVqyWI4sCB\nA8cs9qcojeH7rrVWygD5YIatW7dKde7PPvtMgmxKS0ullNXKlSulvp2vO/fRRx+Jy66qqkqepS1b\nttSbI6KcHNS3iF7t7xvaJ0hQ2TQUXNCuXTvpn1AdQZeSknJMu9p90CumcFE3naIoihJzWsQy8sEK\nixcvlpHfJ598IgED+/btE0tl8+bNsvaFz6mYOXOmjAj79+8vLrZbbrlFyv0E14y55pprAOf+86PH\npUuXsnbtWsBZSb6sig9LHDp0qAQ49OrVS/KWfGFKRWkKM2bMEJedd1fv2LGjzpDvM844gxUrVgDO\npe3dI6+//rrs6wv/tmnThtzcXABuvfVW7rvvvma+E6U10tQcSG+11GdR+/dfSkqKTJFAzWoL3mIK\nWvZBV5+/tnbt2oUVwNCic0bdunVj7969ss37HEtLS8VXvmPHDkkI9NWML7jgApnbiY+Pl3JBDz/8\nMN///vcBmD59OgC/+93vRMArV64Ud8ny5cvF9ZaRkSHlfm6//XbARfG99957gJsz8g/9P//5Tyn3\nryiRMmrUKOmP3t2WmprKzTffDDjXtU/SzsvLkz46e/Zs6Y+eSZMm8Y1vfANw+W++BND48eMlodsP\n9pRTl3AUlI+AC87l1F5mAlxf9W6/2kmtfh+/KkMwwi6YEBucd2oIddMpiqIoMadFLCPvTiguLua2\n224D4I033hAr6eyzz5bKDEVFRUyaNAlAMtPLyspkbZdevXqJ9r3llltYtWoV4CwqcFFI3hrKzMzk\n3XffBeCiiy6Sxfx27Ngho1SfNR8XFyeuk9TU1BqWmI/OU5RIefLJJ6XklB+N5ubmSgWQiooKlixZ\nAjjLyT8fb7/9tvRp78YbOnRojZFpXl4e4Nzf3k3tLSfl1CBYdSHcCgylpaU1Fs/z7eqykhITE2tE\n0wX38a63oNXjjxtcrryioqL1uOm8G2Lz5s3iHjvttNOkTNArr7wikUNdunQRQfjyPJ9++qnM8XTo\n0EHcd927d2fy5MlAdWJgu3btJHw8NzdX3BYjR46U+aNdu3YxfPhwwEUigXvQr7jiCsCFiX/99deA\ncyd6pakokRKMlvNKafny5ZLsumzZMlkq5e6775Z0h4SEBHF/+IX4nn32WR544AHAvRh8xe/y8nKZ\nl1JObupTNMFBSnC+pq59jhw5IhHCBw4cqDFdUtc5/Ps4LS2txnnqUkbBcwWVXDgRftqDFUVRlJjT\nIpaRn2h97bXXJL/izDPP5KOPPgKc5vQWU1JSkgQo+JFhVlaWuM3mz58vGjk7O1vKrngra/v27WIl\nZWdn88477wDw2GOP8dJLLwEuAdZ/9guXvfrqqzICGDVqlEQ1jRgxQpILFaUp+H7uLe/OnTtLv+3X\nrx+zZ88G4N5775XAhu3bt8uCj6effjrg8vHOPfdcoDp3D1xVey2UqnjCcdP5KOI9e/aIizcYHRdM\nZPXEx8fXCHLwFpE/3+HDh8UCKikpEYurvLxcAxgURVGUE4MWsYyeeeYZwOVG+KUZBg8eLIUgly1b\nJp8rKytZsGABUJ2xPmbMGAlaWLFihVhMO3fulPVbfCHVlStXSrWGBQsWSKDCL37xC7mebdu2MXHi\nRKDa+po4caKU5J81a5YsY96pUycp16Iox4OvLNKpUycJspk+fbr46l944QUpGDxhwgTxEPi+f+65\n50rOnp9PBTfy3LVrV8vchNIqCSecOxjg4IvsBi0j/y6svW5RXQQtpODckLeGgpZR2PcQzk7GmN8A\nOaH9HwZWAn8D4oF84AZrbb2LnHsXW3Jysght5syZUvNt7NixfPjhh4BbUM8roaVLlwKwcOFCMStH\njBghZX3atWvH008/DVRXRE5JSZEH9p577uH+++8HXIkfH2lUUlIiSbZ+Iq9Lly7i0ps8ebIsFf3G\nG29IkES0OF55KjVpzfJ87LHH5GH1ymjt2rXiBsnNzRV33DnnnCP1EdetWyeuZ5/k/frrr0tgzZdf\nfillhoqKiiQaNRq0Znkqx095ebkMdHbv3i3TEN6V1qNHjxrRb8EK3rW3BSkrK5OBVTBiL1waddMZ\nYy4CBltrRwOTgCeAXwL/11qbA2wCvhfRWU9hVJ7RReUZXVSeSqwIxzJ6H1gR+rwfaAeMA24LbZsD\n3AM8Vd8BvGXx3HPP1Vi3yOf9ZGZmyrpEL730Uo3ABXDlhHwI9rp162RVV6gOzf7xj38s5/DbCgoK\nuPLKKwEX4OALqAbNRx9Wu3nzZinAunjxYq677jrAufT8arA+rPY4OW55KjVo1fJMSUkhKSkJqC6x\nkpSUJEV5e/fuLVZNUlKSTCIfOXKEs88+G6ieRJ41a5bk3gVX12zfvj1FRUXRuuRWLc9TlbrcZg25\n5hoqrFpeXi5uusLCQlk/zpf9iY+Pl8/eOoe6rSGodiOXlJTUcAU2Vtz1mGtubAdrbQXg3943A28D\nlwbM9N1AZkPH8HNGXbp0EZddUVERAwYMAJyC8T70vn37Sl7F6tWrARg4cKAca/LkyRKJVFFRIQ+s\nj8bLzMyU8j3FxcVS1+vOO++sES3nzVSf1zFgwACJerrhhhskmq68vFzmnaJBNOSpVNPa5TlnzhxJ\nmvb1wKqqquRB3bt3r0R/JiUlSRL3wYMHZd7S58rdc889Mp8aXKq8tLQ0rKTCcGjt8lRqUl+ia2MK\nwCuWgwcPypy4d/vWXi7cu+8iqQyfkJAgfTK4gF+DbcI9uDHmGlznvAT4IvCVLoPaBFSe0UXlGV1U\nnkpLE24Aw6XA/cAka+0BY0yxMaattfYw0BPY0VB7H+lWWVkpC5BZa8VK6tGjRw2Tzlsrvt2iRYsk\n2OHNN9+Uat8bNmyQAAS/qNiSJUukkvevfvUrOUZ+fr7kO3344YeMGzcOqC618vbbb0u177y8PAlw\n8NcXTY5XnkpNWrM809PTpQKJzxc6evSolLfq0qWLVGNYuHAhv/nNb6TtzJkzgeoRaVZWluTp1cb3\n82jQmuWpVBOu+6v2/sFoueLiYlmgNJhn5K2atLQ0eTcHrZu6iqoGP1dUVNQoIxROtF+jexhj0oFH\ngQnWWl8XJxf4JvBfof/nNXSMzExn1a9du1bcY0OGDJHyPBs3bpSbHz58OBdeeCEAL7/8MuDcFD5a\nbv/+/VLVe/jw4ZK86ueBjhw5Qt++fQH405/+JP7Q6dOny/GGDx8uitALacWKFeJOGTx4sNT9Sk5O\nFv9qNIiGPJVqWrs8g1GjvjJ9YWGh9Ltly5ZJlF19eJdKfYooMzNTXHrHS2uX56lKJPMv9ZUCqk8h\n+HdyMBHWzxkVFxfLuzk5OblGzbpgQmxj1xMVZQRMA7oArwSWUrgJeM4Y831gK/BiWFelgMoz2qg8\no4vKU4kJbXyyaXMyYsSIKnBa1o/yevbsKYEK8fHxEpPuIzOgelG+1NRUKY66bds2KYSalZUl7jQ/\noVtQUCBFVzt06CBrKRUUFIgZOmPGDJ56ygUDBWPhg+u3+1Fsdna2uOkeeuihVuMvb9OmTfP/cC1A\nVVVVq5Bpc8rTu9C89d6mTRux9FevXl0jMu54ORXk2ZK0FnmmpKQ0Ks+63GX1WVJ+e0pKilg+Pset\nb9++0j/79Okj0yZpaWkSGQrVFnsw0dUft6ysrM61j370ox/VK88WqcDg53WgOnO8qKhIqi706dNH\nPg8aNEjcFn7pCb/MA0DXrl1FeNZaqdF17bXXAm5uqH///gA8//zzEqIdXLHwkUceEcH7ml7BJK3O\nnTvL58LCwmiGzSqnIHW54bzVUV+4LFQvxuddxlBdlST4TA0ePFgGa8rJSVDRNLZsRGMusdoVvj3B\n5R/81ETt1Vu9my4+Pl4Mh7oUXu3ouXCi6bQ2naIoihJzWsQy8hO4BQUFUv+trKxMTMH8/HyZRBs5\ncqTUSvIutq5du8oxFixYIJp4yJAhYjX5/IspU6ZIFeQ77rhDrqGwsFDWf/npT3/K448/DlRP3mVn\nZ0tARf/+/SUhd9q0abz4orrIT3Z8VKWPLGpuvIVz3nnnSWLh/Pnza7ipfemfIHWNMIcMGVIj+lM5\nuYnECqrLXVdfTpJ/FxYXF4vrLbgWUe0giLoW5fPfh1PfrjZqGSmKoigxp0UsIz/Hs2XLFskH2rVr\nV41Rns8yf+ONN2TVyquuugqA2bNniw+zsrKSnJwcwM0ZeT+nX421Q4cOco6qqirJaO/Vq5dUNs7N\nzZXcj2effRZw2ce+ori1VsoWFRcXS0CEcvLSUhaRx8/55Ofn8/DDDwNupOmL9ULd80l+MtmnJoDr\nrxdffHFzXq4SYxoLSAjHQmrMUgnmHvmgmv3798tce3JyckTWTtBKCmv/sI98HPgHferUqVKdOy4u\nThJg4+LipBzQvn37auQfgYvJRafkAAAFy0lEQVTi8Irptdde47333gNcQqFPJPT1vbZs2SIKaP/+\n/dx2myupdccdd8hyEwkJCZJ/5OvR7d+/X14QGzdulFym1NRUXbjsFMBXxm7Xrl1U88rqY9GiRXJe\nX7IqqIjqIj09XVzYQT7++GO++MIVSXj00UejfKXKyUJjCs0Pfo4cOSLKaO/evVIrNFhyqr7F8uqr\noacBDIqiKMoJQYvkGV122WVV4CwOH3CQmZnJ2rVrARfX7kejH3/8Meeffz5QHcCwceNG8vPzAcjJ\nyZFM9MrKStHQPgy2qKhIvk9OTmbGjBmAKx3k9+3WrZtYa/4c7dq149133wXcpLIP/Z47d664/Z5/\n/vlWkXMAmscRbZpLnklJSWLpHy9BK33Hjror8pzs8mxpWos8O3bseNzybMzF5i2n5ORkef9lZWXJ\nlEXPnj1ruOxqHze4nlFFRYVYQwkJCZLjeeONN8Y2z8hHBaWlpYn7a8OGDZJMmpiYKG6zQYMGiYno\nE6xycnJYsmQJ4KKevNAOHDjAsmXLauw7YsQIcVmcfvrp4rIbPXq0RCpVVlaK790LLDk5WXKgdu7c\nKUmvWVlZUa9Np7Q+fGJqY6V5IqU+ReSVSr9+/aQKfVlZmWz3Luwghw4dkogn5dTCv6cayktrjEhK\nCnmlcuDAASlOkJaWVqM0UO25oNrX5v8Od85I3XSKoihKzGkRy8jnE+3du1espDPOOEMWGMvIyJA1\niw4dOiRWiZ84W7VqlWjZF154gYkTJwKumvaYMWMAZE2YTZs2MXbsWMCVt/CjzgMHDohb8MwzzxS3\nnnf/dejQQSaxzzrrLFlLqX///lFzsyitl+DaQd6FG2nxUV+myq8PA67/+P7v3cTvvPNOjcr0vn8N\nHTpUAhvAeQmg2rNw+PBhcRkXFBRI0E779u1r5CcpiidoUYW7QF95ebkElO3fv1+CZtLT08XdFlyv\nKNiuruNFs1DqcePDrgsKCkQge/bskUS9Tp06idLo27evJLj6xMBt27bJA11YWChKbOzYseLP9Me1\n1opZOX78eHlgS0pKRCClpaWSfDtnzhzAJb366zl48KCsMltWViblhZSTFz93mJKSIsqhIWXkBy6+\nX06dOlUSZ1etWsVf//pXwK3u6kv/BGvU+T7VtWtXrr/+esD1Ra/QysvLxT3s53XXr1/P8uXLj7mW\nK664QpabUE5Ogi/zoDusLvddfHx8ne68+tx0dR3Du+mSkpJk2qSwsLCGAvKKqbHrDVcZqZtOURRF\niTktEk2nKIqiKA2hlpGiKIoSc1QZKYqiKDFHlZGiKIoSc1QZKYqiKDFHlZGiKIoSc1QZKYqiKDGn\nRZJejTGPA6OAKuCH1tqVLXHeBq7nN0AO7v4fBq4GRgC+Pv+j1tq5Mbq8RlF5RheVZ/RRmSqR0uzK\nyBhzIZBtrR1tjDkLeB4Y3dznbeB6LgIGh66nM7Aa+CfwM2vtW7G6rnBReUYXlWf0UZkqTaEl3HTj\ngdcBrLUbgE7GmA4tcN76eB+4LvR5P9AOaHzlp9aDyjO6qDyjj8pUiZiWcNN1B1YF/i4IbTvYAuc+\nBmttBVAS+vNm4G2gArjLGPNvwG7gLmtty65DHT4qz+ii8ow+KlMlYmIRwNAqFqsyxlyD65h3AX8D\nfmqtvRj4BHgwhpcWKSrP6KLyjD4qU6VRWsIy2oEbFXl6APktcN56McZcCtwPTLLWHgAWBr5+E3gq\nJhcWHirP6KLyjD4qUyViWsIymg98C8AYMxzYYa0taoHz1okxJh14FLjSWrs3tO1VY4xfJ2Ic8FmM\nLi8cVJ7RReUZfVSmSsQ0u2VkrV1qjFlljFkKVAJ3Nvc5G2Ea0AV4xa8zA/wFmGWMOQQUA/8jRtfW\nKCrP6KLyjD4qU6Up6BISiqIoSszRCgyKoihKzFFlpCiKosQcVUaKoihKzFFlpCiKosQcVUaKoihK\nzFFlpCiKosQcVUaKoihKzFFlpCiKosSc/w/CVKh7dPSxzwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 5 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"colab_type":"text","id":"SwEup79kvLU7"},"cell_type":"markdown","source":["## Plot sample image"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":1980,"status":"ok","timestamp":1549193756118,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"FCjox0bzvNx0","outputId":"e73da263-62f7-4a32-f3de-864f8918c0dd","colab":{"base_uri":"https://localhost:8080/","height":166}},"cell_type":"code","source":["if plot == True:\n","  plot_denoise(denoise_model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAW8AAACECAYAAABfyKrhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZZAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 3 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"colab_type":"text","id":"EQ95ZW18rS3I"},"cell_type":"markdown","source":["## Save Weights"]},{"metadata":{"colab_type":"code","id":"Yerm9hvwrZ1B","colab":{}},"cell_type":"code","source":["if denoise_train == True:\n","  denoise_model.save('improved_denoise_complete.h5')\n","  denoise_model.save_weights('improved_denoise.h5')\n","  with open('improved_denoise_history.pck', 'wb') as file_pi:\n","    pickle.dump(denoise_history, file_pi)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"LqdBp7CwN0YA"},"cell_type":"markdown","source":["## Plot Loss"]},{"metadata":{"colab_type":"code","id":"jcCA05YxPbX9","colab":{}},"cell_type":"code","source":["# Summarize history for loss\n","# NOTE: does not work on Google Colab, please refer to the report\n","if plot == True:\n","  plt.plot(denoise_history['loss'])\n","  plt.plot(denoise_history['val_loss'])\n","  plt.title('Improved model loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend(['Train', 'Validation'], loc='upper left')\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"SYmXCthWr0py"},"cell_type":"markdown","source":["# Training: Descriptor model\n","\n","For the collection of the results that gave the starting insight the parameters are summarized in the first comment. We define a set of callbacks to limit the training such that the model avoids overfitting/underfitting.\n","\n","## Loading of data\n","\n"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":93704,"status":"ok","timestamp":1549191324675,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"1QB_kKlCeQf1","outputId":"c536ef22-fa0d-4c92-8245-98d7eebb8b13","colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["if descriptor_train == True:\n","  hPatches = HPatches(train_fnames = train_fnames, test_fnames = test_fnames)\n","  descriptor_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 1), num_triplets = 100000)\n","  descriptor_generator_val = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 0), num_triplets = 10000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:35<00:00,  2.75it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["97435\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:01<00:00, 70909.78it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:22<00:00,  5.20it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["59532\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 69433.61it/s]\n"],"name":"stderr"}]},{"metadata":{"colab_type":"code","id":"-TFwvZL4r4dR","colab":{}},"cell_type":"code","source":["# Training: steps_per_epoch = 2000, validation_steps = 200, epochs = 20\n","# Collection of results as plotted in figures:: steps_per_epoch = 2000, validation_steps = 200, epochs = 2\n","\n","descriptor_model_connected, descriptor_model = get_descriptor_model_connected(SHAPE, descriptor_depth)\n","descriptor_history = None\n","def lr_schedule_descriptor(epoch):\n","    initial_lr = 0.0001\n","    if epoch<=5:\n","        lr = initial_lr\n","    elif epoch<=10:\n","        lr = initial_lr/10\n","    elif epoch<=15:\n","        lr = initial_lr/20 \n","    else:\n","        lr = initial_lr/20 \n","    return lr\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 3, mode= 'auto')\n","lr_scheduler = LearningRateScheduler(lr_schedule_descriptor)\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","callbacks_list = [early_stopping, lr_scheduler, lr_reducer]\n","\n","descriptor_model_connected.compile(loss=\"mean_squared_error\", optimizer=Adam(0.001))\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":1955,"status":"ok","timestamp":1549197959183,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"_B0sbzwqPbVd","outputId":"887dfcec-6898-4b93-c117-525dc29f3321","colab":{"base_uri":"https://localhost:8080/","height":2601}},"cell_type":"code","source":["# Plot the architecture of the model together with its summary and number of trainable parameters\n","if plot == True:\n","  plot_model(descriptor_model, to_file='improved_descriptor_arch.png')\n","  print(descriptor_model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            (None, 32, 32, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_122 (Conv2D)             (None, 32, 32, 8)    80          input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 32, 32, 8)    32          conv2d_122[0][0]                 \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 32, 32, 8)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_123 (Conv2D)             (None, 32, 32, 8)    72          activation_106[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 32, 32, 8)    32          conv2d_123[0][0]                 \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 32, 32, 8)    0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_124 (Conv2D)             (None, 32, 32, 8)    584         activation_107[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 32, 32, 8)    32          conv2d_124[0][0]                 \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 32, 32, 8)    0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 32, 32, 32)   288         activation_106[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_125 (Conv2D)             (None, 32, 32, 32)   288         activation_108[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 32, 32, 32)   0           conv2d_126[0][0]                 \n","                                                                 conv2d_125[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 32, 32, 32)   128         add_7[0][0]                      \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 32, 32, 32)   0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 32, 32, 8)    264         activation_109[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 32, 32, 8)    32          conv2d_127[0][0]                 \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 32, 32, 8)    0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 32, 32, 8)    584         activation_110[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 32, 32, 8)    32          conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 32, 32, 8)    0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 32, 32, 32)   288         activation_111[0][0]             \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 32, 32, 32)   0           add_7[0][0]                      \n","                                                                 conv2d_129[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 32, 32, 32)   128         add_8[0][0]                      \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 32, 32, 32)   0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_130 (Conv2D)             (None, 16, 16, 32)   1056        activation_112[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 16, 16, 32)   128         conv2d_130[0][0]                 \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 16, 16, 32)   0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_131 (Conv2D)             (None, 16, 16, 32)   9248        activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 16, 16, 32)   128         conv2d_131[0][0]                 \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 16, 16, 32)   0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_133 (Conv2D)             (None, 16, 16, 64)   2112        add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_132 (Conv2D)             (None, 16, 16, 64)   2112        activation_114[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 16, 16, 64)   0           conv2d_133[0][0]                 \n","                                                                 conv2d_132[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 16, 16, 64)   256         add_9[0][0]                      \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_134 (Conv2D)             (None, 16, 16, 32)   2080        activation_115[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 16, 16, 32)   128         conv2d_134[0][0]                 \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 16, 16, 32)   0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_135 (Conv2D)             (None, 16, 16, 32)   9248        activation_116[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 16, 16, 32)   128         conv2d_135[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 16, 16, 32)   0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_136 (Conv2D)             (None, 16, 16, 64)   2112        activation_117[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 16, 16, 64)   0           add_9[0][0]                      \n","                                                                 conv2d_136[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 16, 16, 64)   256         add_10[0][0]                     \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 16, 16, 64)   0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_137 (Conv2D)             (None, 8, 8, 64)     4160        activation_118[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 8, 8, 64)     256         conv2d_137[0][0]                 \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 8, 8, 64)     0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_138 (Conv2D)             (None, 8, 8, 64)     36928       activation_119[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_120 (BatchN (None, 8, 8, 64)     256         conv2d_138[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 8, 8, 64)     0           batch_normalization_120[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_140 (Conv2D)             (None, 8, 8, 128)    8320        add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_139 (Conv2D)             (None, 8, 8, 128)    8320        activation_120[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 8, 8, 128)    0           conv2d_140[0][0]                 \n","                                                                 conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_121 (BatchN (None, 8, 8, 128)    512         add_11[0][0]                     \n","__________________________________________________________________________________________________\n","activation_121 (Activation)     (None, 8, 8, 128)    0           batch_normalization_121[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_141 (Conv2D)             (None, 8, 8, 64)     8256        activation_121[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_122 (BatchN (None, 8, 8, 64)     256         conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 8, 8, 64)     0           batch_normalization_122[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_142 (Conv2D)             (None, 8, 8, 64)     36928       activation_122[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_123 (BatchN (None, 8, 8, 64)     256         conv2d_142[0][0]                 \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 8, 8, 64)     0           batch_normalization_123[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_143 (Conv2D)             (None, 8, 8, 128)    8320        activation_123[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 8, 8, 128)    0           add_11[0][0]                     \n","                                                                 conv2d_143[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_124 (BatchN (None, 8, 8, 128)    512         add_12[0][0]                     \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 8, 8, 128)    0           batch_normalization_124[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_144 (Conv2D)             (None, 1, 1, 128)    1048704     activation_124[0][0]             \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 128)          0           conv2d_144[0][0]                 \n","==================================================================================================\n","Total params: 1,193,840\n","Trainable params: 1,192,096\n","Non-trainable params: 1,744\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"qQ-OaI_m5iyK","colab":{}},"cell_type":"code","source":["# If previously defined that we are training, train it from scratch\n","# If not simply load the history from a file\n","if descriptor_train == True:\n","  descriptor_history = descriptor_model_connected.fit_generator(generator=descriptor_generator,\n","                                                                callbacks=callbacks_list,\n","                                                                epochs=20, verbose=1,\n","                                                           validation_data=descriptor_generator_val,\n","                                                           workers=1,\n","                                                           steps_per_epoch = 2000,\n","                                                           validation_steps = 200,\n","                                                           use_multiprocessing=False,)\n","else:\n","  with open('improved_descriptor_history.pck', 'rb') as file_pi:\n","    descriptor_history = pickle.load(file_pi)\n","  descriptor_model.load_weights('improved_descriptor.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"HM07D1RzrdZd"},"cell_type":"markdown","source":["## Save Weights"]},{"metadata":{"colab_type":"code","id":"BUVX0UXTrcYs","colab":{}},"cell_type":"code","source":["if descriptor_train == True:\n","  descriptor_model.save_weights('improved_descriptor.h5')\n","  with open('improved_descriptor_history.pck', 'wb') as file_pi:\n","    pickle.dump(descriptor_history, file_pi)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"nPJWkDHuO37t"},"cell_type":"markdown","source":["## Plot Loss"]},{"metadata":{"colab_type":"code","id":"R2qkucrJPR2z","colab":{}},"cell_type":"code","source":["# Summarize history for loss\n","# NOTE: does not work on Google Colab, please refer to the report\n","if plot == True:\n","  plt.plot(descriptor_history.history['loss'])\n","  plt.plot(descriptor_history.history['val_loss'])\n","  plt.title('Improved model loss - Descriptor')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend(['Train', 'Validation'], loc='upper left')\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"uKh2DU5Cvx6m"},"cell_type":"markdown","source":["# Evaluation"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":1373454,"status":"ok","timestamp":1549197012401,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"kPQkmrFbv21_","outputId":"c52b2aed-6f57-417a-b248-dfede3674290","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Just in case remove any previous results, such that the results are freshly generated and not biased from aprevious run\n","!rm -rf out/\n","!rm -rf results/\n","generate_desc_csv(descriptor_model, denoise_model, seqs_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [52:56<00:00, 78.33s/it]\n"],"name":"stderr"}]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":111040,"status":"ok","timestamp":1549191358411,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"YgDUXdPolvLP","outputId":"4d6a4395-89cd-4635-9a30-699f86ea616b","colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["!git clone https://github.com/hpatches/hpatches-benchmark"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'hpatches-benchmark'...\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (21/21), done.\u001b[K\n","remote: Total 1435 (delta 11), reused 14 (delta 5), pack-reused 1409\u001b[K\n","Receiving objects: 100% (1435/1435), 239.72 MiB | 20.10 MiB/s, done.\n","Resolving deltas: 100% (789/789), done.\n","Checking out files: 100% (135/135), done.\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"nakxQPmQwIYU"},"cell_type":"markdown","source":["## Verification\n"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":365388,"status":"ok","timestamp":1549197377788,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"LsL5vQWdwLMD","outputId":"9afb88e5-3ebf-4733-b331-0d6807d802bd","colab":{"base_uri":"https://localhost:8080/","height":391}},"cell_type":"code","source":["!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n","!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=verification"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n",">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",">> Please wait, loading the descriptor files...\n",">> Descriptor files loaded.\n",">> Evaluating \u001b[32mverification\u001b[0m task\n","Processing verification task 1/3 : 100% 1000000/1000000 [01:39<00:00, 10074.95it/s]\n","Processing verification task 2/3 : 100% 1000000/1000000 [01:39<00:00, 10086.08it/s]\n","Processing verification task 3/3 : 100% 1000000/1000000 [01:39<00:00, 10052.46it/s]\n",">> \u001b[32mVerification\u001b[0m task finished in 307 secs  \n","\u001b[32mVerification\u001b[0m task results:\n","\u001b[34mCUSTOM\u001b[0m - Balanced variant (auc) \n","Noise       Inter     Intra\n","-------  --------  --------\n","Easy     0.943892  0.914343\n","Hard     0.92641   0.889426\n","Tough    0.897927  0.852676\n","\u001b[34mCUSTOM\u001b[0m - Imbalanced variant (ap) \n","Noise       Inter     Intra\n","-------  --------  --------\n","Easy     0.852566  0.770472\n","Hard     0.795039  0.683262\n","Tough    0.71381   0.583898\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"6nxmNtwVwMW0"},"cell_type":"markdown","source":["## Retrieval"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":333101,"status":"ok","timestamp":1549197710888,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"bRnuGHJawPjj","outputId":"3f019175-41b0-484a-85e7-076dbe3f274e","colab":{"base_uri":"https://localhost:8080/","height":343}},"cell_type":"code","source":["!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n","!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=retrieval"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n",">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",">> Please wait, loading the descriptor files...\n",">> Descriptor files loaded.\n",">> Evaluating \u001b[32mretrieval\u001b[0m task\n",">> Please wait, computing distance matrix...\n","tcmalloc: large alloc 1600004096 bytes == 0x26842000 @  0x7f64ea9df1e7 0x7f64e011dde1 0x7f64e0182868 0x7f64e0182e37 0x7f64e021cc48 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f64ea5dcb97 0x5afa0a\n",">> Distance matrix done.\n","Processing retrieval task: 100% 10000/10000 [04:05<00:00, 40.81it/s]\n",">> \u001b[32mRetrieval\u001b[0m task finished in 264 secs  \n","\u001b[32mRetrieval\u001b[0m task results:\n","\u001b[34mCUSTOM\u001b[0m - mAP 10K queries \n","Noise         100       500      1000      5000     10000     15000     20000\n","-------  --------  --------  --------  --------  --------  --------  --------\n","Easy     0.772724  0.634988  0.579343  0.459781  0.413209  0.38837   0.373258\n","Hard     0.714858  0.534951  0.461671  0.31055   0.258242  0.231016  0.215609\n","Tough    0.626979  0.414284  0.335779  0.194709  0.152096  0.131615  0.120169\n","mean     0.704854  0.528074  0.458931  0.32168   0.274516  0.250334  0.236345\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"KmVP-9yyq2mi"},"cell_type":"markdown","source":["## Matching"]},{"metadata":{"colab_type":"code","executionInfo":{"elapsed":187645,"status":"ok","timestamp":1549197898532,"user":{"displayName":"Martin Ferianc","photoUrl":"https://lh6.googleusercontent.com/-iRTaL7t7S7w/AAAAAAAAAAI/AAAAAAAAXfM/7-kx--8D2ls/s64/photo.jpg","userId":"00860128407176767106"},"user_tz":0},"id":"ES1T7u45q4se","outputId":"92db251a-cecf-4fc4-a689-fd32e38c27be","colab":{"base_uri":"https://localhost:8080/","height":255}},"cell_type":"code","source":["!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n","!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=matching"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n",">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",">> Please wait, loading the descriptor files...\n",">> Descriptor files loaded.\n",">> Evaluating \u001b[32mmatching\u001b[0m task\n","100% 40/40 [02:12<00:00,  4.50s/it]\n",">> \u001b[32mMatching\u001b[0m task finished in 133 secs  \n","\u001b[32mMatching\u001b[0m task results:\n","\u001b[34mCUSTOM\u001b[0m - mAP \n","    Easy       Hard      Tough      mean\n","--------  ---------  ---------  --------\n","0.227388  0.0987057  0.0408514  0.122315\n","\n","\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"gSX1l0YKwR4h"},"cell_type":"markdown","source":["## Compressing and saving the CSV files "]},{"metadata":{"colab_type":"code","id":"e1yNnjZFqbGo","colab":{}},"cell_type":"code","source":["!zip -rq descriptors.zip ./out/custom"],"execution_count":0,"outputs":[]}]}